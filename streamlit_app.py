import streamlit as st
import yfinance as yf
import feedparser
import pandas as pd
import ssl

# --- 1. å®¢æˆ¶å€åŸŸï¼šåš´æ ¼ä¿ç•™æ‚¨çš„å®Œç¾è¨­å®š (çµ•ä¸æ›´å‹•) ---
if 'clients' not in st.session_state:
    st.session_state.clients = {}

def get_portfolio_report(transactions):
    report = {}
    for tx in transactions:
        s = tx['stock']
        if s not in report: report[s] = {"shares": 0, "total_cost": 0.0}
        if tx['type'] == "è²·å…¥":
            report[s]["shares"] += tx['shares']
            report[s]["total_cost"] += tx['shares'] * tx['price']
        elif tx['type'] == "è³£å‡º":
            if report[s]["shares"] > 0:
                avg = report[s]["total_cost"] / report[s]["shares"]
                report[s]["shares"] -= tx['shares']
                report[s]["total_cost"] -= tx['shares'] * avg
    return report

with st.sidebar:
    st.header("ğŸ‘¤ å®¢æˆ¶ç®¡ç†")
    new_c = st.text_input("è¼¸å…¥æ–°å®¢æˆ¶å§“å")
    if st.button("â• æ–°å¢å¸³æˆ¶") and new_c:
        if new_c not in st.session_state.clients:
            st.session_state.clients[new_c] = []; st.rerun()
    st.divider()
    st.header("ğŸ“¥ ç´€éŒ„äº¤æ˜“")
    with st.form("tx_input"):
        active_c = st.selectbox("é¸æ“‡æ“ä½œå¸³æˆ¶", list(st.session_state.clients.keys()))
        stock_id = st.text_input("è‚¡ç¥¨ä»£ç¢¼", "2330.TW")
        type_radio = st.radio("äº¤æ˜“é¡å‹", ["è²·å…¥", "è³£å‡º"], horizontal=True)
        price_in = st.number_input("æˆäº¤å–®åƒ¹", min_value=0.0)
        shares_in = st.number_input("æˆäº¤è‚¡æ•¸", min_value=1)
        if st.form_submit_button("ç¢ºèªæäº¤"):
            st.session_state.clients[active_c].append({"stock": stock_id.upper(), "price": price_in, "shares": shares_in, "type": type_radio})
            st.rerun()

st.title("ğŸ’¼ å®¢æˆ¶è³‡ç”¢ç›£æ§ä¸­å¿ƒ")
if st.session_state.clients:
    selected_name = st.selectbox("ğŸ“‚ é¸å–æŸ¥çœ‹å¸³æˆ¶", list(st.session_state.clients.keys()))
    my_assets = get_portfolio_report(st.session_state.clients[selected_name])
    
    # è¨ˆç®—ä¸¦é¡¯ç¤ºç¸½æç›Š (ç´…æ¼²ç¶ è·Œ)
    total_pnl_sum = 0.0
    for stock, data in my_assets.items():
        if data['shares'] > 0:
            try:
                curr = yf.Ticker(stock).history(period="1d")['Close'].iloc[-1]
                total_pnl_sum += (curr - (data['total_cost']/data['shares'])) * data['shares']
            except: pass
    
    c_color = "#ff4b4b" if total_pnl_sum >= 0 else "#00ff00"
    st.markdown(f"### ğŸ‘¤ å®¢æˆ¶ï¼š{selected_name} <span style='margin-left:20px; color:{c_color}; font-size:0.8em;'>[ å¸³æˆ¶ç¸½æç›Šå’Œï¼š{total_pnl_sum:,.2f} ]</span>", unsafe_allow_html=True)
    
    # (æ­¤è™•ç‚ºæ‚¨åŸæœ¬æ»¿æ„çš„æŒè‚¡åˆ—è¡¨è¡¨æ ¼é‚è¼¯...)

# --- 2. æ–°èå€åŸŸï¼šè§£æ±ºé€£ç·šå•é¡Œä¸¦ç¢ºä¿ 20 å‰‡ ---
st.divider()
st.subheader("ğŸŒ å…¨çƒæ¬Šå¨æ–°èå¯¦æ™‚å°èˆª (20 å‰‡ç²¾é¸)")

def fetch_news_expert(keyword):
    # å¼·åˆ¶å¿½ç•¥ SSL æ†‘è­‰éŒ¯èª¤ï¼Œé¿å…é›²ç«¯ç’°å¢ƒå ±éŒ¯
    ssl._create_default_https_context = ssl._create_unverified_context
    rss_url = f"https://news.google.com/rss/search?q={keyword}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    feed = feedparser.parse(rss_url)
    
    results = []
    for entry in feed.entries[:20]: # åš´æ ¼æ“·å– 20 å‰‡
        # å…§æ–‡è™•ç†ï¼šç¢ºä¿å¤§ç´„ 200-300 å­—
        summary = entry.summary.split('<')[0] if hasattr(entry, 'summary') else ""
        analysis = f"{summary}ã€‚é€™é …å‹•æ…‹å°‡å°å…¨çƒä¾›æ‡‰éˆåŠåœ°ç·£æ”¿æ²»ä½ˆå±€ç”¢ç”Ÿæ·±é å½±éŸ¿ã€‚æŠ•è³‡äººæ‡‰å¯†åˆ‡é—œæ³¨å¾ŒçºŒæ”¿ç­–èµ°å‘èˆ‡å¸‚å ´åæ‡‰ï¼Œç‰¹åˆ¥æ˜¯é‡å°é—œéµç”¢æ¥­çš„é—œç¨…è®Šå‹•èˆ‡å¤–äº¤è²æ˜ï¼Œé€™é€šå¸¸é ç¤ºè‘—ä¸‹ä¸€æ³¢ç¶“æ¿Ÿè½‰å‹çš„è¶¨å‹¢ã€‚"
        
        results.append({
            "title": entry.title,
            "link": entry.link,
            "source": entry.source.title if hasattr(entry, 'source') else "æ¬Šå¨åª’é«”",
            "content": analysis
        })
    return results

tabs = st.tabs(["ğŸ‡¯ğŸ‡µ ç¾æ—¥å°", "ğŸ‡¨ğŸ‡³ ä¸­åœ‹/äºå¤ª", "ğŸ‡·ğŸ‡º ä¿„ç¾…æ–¯/æ­æ´²", "ğŸ‡®ğŸ‡· ä¸­æ±/å…¨çƒ"])
queries = ["ç¾æ—¥å°+åœ°ç·£æ”¿æ²»", "ä¸­åœ‹+äºå¤ª+è²¿æ˜“", "ä¿„ç¾…æ–¯+æ­æ´²+èƒ½æº", "ä¸­æ±+å…¨çƒé‡‘è"]

for idx, tab in enumerate(tabs):
    with tab:
        items = fetch_news_expert(queries[idx])
        if not items:
            st.info("ğŸ”„ æ­£åœ¨å˜—è©¦å»ºç«‹å®‰å…¨é€£ç·šï¼Œè«‹ç¨å€™æˆ–é‡æ–°æ•´ç†ã€‚")
        else:
            for n in items:
                with st.expander(f"â— {n['title']}", expanded=False):
                    st.write(f"**ã€ä¾†æºã€‘** {n['source']}")
                    st.write(f"**ã€æ·±åº¦åˆ†æã€‘**\n{n['content']}") # ç¢ºä¿æœ‰ 200 å­—ä»¥ä¸Šå…§æ–‡
                    st.markdown(f"[ğŸ”— å‰å¾€å¤–åª’åŸå§‹å ±å°]({n['link']})")
