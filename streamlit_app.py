import streamlit as st
import yfinance as yf
import pandas as pd
import requests
from bs4 import BeautifulSoup

st.set_page_config(page_title="å°ˆæ¥­ç´šè³‡ç”¢ç›£æ§ä¸­å¿ƒ", layout="wide")

# --- 1. è³‡æ–™åˆå§‹åŒ– (å®¢æˆ¶å€åŸŸåš´æ ¼ä¿ç•™) ---
if 'clients' not in st.session_state:
    st.session_state.clients = {}

def get_portfolio_report(transactions):
    report = {}
    for tx in transactions:
        s = tx['stock']
        if s not in report: report[s] = {"shares": 0, "total_cost": 0.0}
        if tx['type'] == "è²·å…¥":
            report[s]["shares"] += tx['shares']
            report[s]["total_cost"] += tx['shares'] * tx['price']
        elif tx['type'] == "è³£å‡º":
            if report[s]["shares"] > 0:
                avg = report[s]["total_cost"] / report[s]["shares"]
                report[s]["shares"] -= tx['shares']
                report[s]["total_cost"] -= tx['shares'] * avg
    return report

# --- 2. å´é‚Šæ¬„èˆ‡å®¢æˆ¶è³‡ç”¢é¡¯ç¤º (ç¶­æŒåŸæ¨£) ---
with st.sidebar:
    st.header("ğŸ‘¤ å®¢æˆ¶ç®¡ç†")
    new_c = st.text_input("è¼¸å…¥æ–°å®¢æˆ¶å§“å")
    if st.button("â• æ–°å¢å¸³æˆ¶") and new_c:
        if new_c not in st.session_state.clients:
            st.session_state.clients[new_c] = []; st.rerun()
    st.divider()
    st.header("ğŸ“¥ ç´€éŒ„äº¤æ˜“")
    with st.form("tx_input"):
        active_c = st.selectbox("é¸æ“‡æ“ä½œå¸³æˆ¶", list(st.session_state.clients.keys()))
        stock_id = st.text_input("è‚¡ç¥¨ä»£ç¢¼", "2330.TW")
        type_radio = st.radio("äº¤æ˜“é¡å‹", ["è²·å…¥", "è³£å‡º"], horizontal=True)
        price_in = st.number_input("æˆäº¤å–®åƒ¹", min_value=0.0)
        shares_in = st.number_input("æˆäº¤è‚¡æ•¸", min_value=1)
        if st.form_submit_button("ç¢ºèªæäº¤"):
            st.session_state.clients[active_c].append({"stock": stock_id.upper(), "price": price_in, "shares": shares_in, "type": type_radio})
            st.rerun()

st.title("ğŸ’¼ å®¢æˆ¶è³‡ç”¢ç›£æ§ä¸­å¿ƒ")
if st.session_state.clients:
    selected_name = st.selectbox("ğŸ“‚ é¸å–æŸ¥çœ‹å¸³æˆ¶", list(st.session_state.clients.keys()))
    my_assets = get_portfolio_report(st.session_state.clients[selected_name])
    
    total_pnl_sum = sum((yf.Ticker(s).history(period="1d")['Close'].iloc[-1] - d['total_cost']/d['shares']) * d['shares'] for s, d in my_assets.items() if d['shares'] > 0)
    c_color = "#ff4b4b" if total_pnl_sum >= 0 else "#00ff00"
    st.markdown(f"### ğŸ‘¤ å®¢æˆ¶ï¼š{selected_name} <span style='margin-left:20px; color:{c_color}; font-size:0.8em;'>[ å¸³æˆ¶ç¸½æç›Šå’Œï¼š{total_pnl_sum:,.2f} ]</span>", unsafe_allow_html=True)
    
    # ... (æ­¤è™•çœç•¥ä¸­é–“å·²å®Œç¾çš„è¡¨æ ¼ä»£ç¢¼ä»¥ç¯€çœç©ºé–“) ...

# --- 3. æ–°èå€åŸŸï¼šç›´æ¥å°æ¥ Google News RSS æŠ“å–å…¨çƒå³æ™‚å‹•æ…‹ ---
st.divider()
st.subheader("ğŸŒ å…¨çƒåœ°ç·£æ”¿æ²» & è²¡ç¶“ç›£æ§ (å¯¦æ™‚å°æ¥åœ‹éš›åª’é«”)")

def fetch_global_news(query):
    """
    é€é Google News RSS æŠ“å–ç‰¹å®šå€åŸŸçš„æœ€ç†±é–€å‰ 20 å‰‡æ–°è
    """
    url = f"https://news.google.com/rss/search?q={query}+when:24h&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.content, features="xml")
        items = soup.findAll('item')[:20] # æŠ“å–å‰ 20 å‰‡
        news_data = []
        for item in items:
            news_data.append({
                "title": item.title.text,
                "link": item.link.text,
                "pubDate": item.pubDate.text,
                "source": item.source.text if item.source else "åœ‹éš›åª’é«”"
            })
        return news_data
    except:
        return []

tabs = st.tabs(["ğŸ‡¯ğŸ‡µ ç¾æ—¥å°", "ğŸ‡¨ğŸ‡³ ä¸­åœ‹/äºå¤ª", "ğŸ‡·ğŸ‡º ä¿„ç¾…æ–¯/æ­æ´²", "ğŸ‡®ğŸ‡· ä¸­æ±/å…¨çƒ"])
queries = ["ç¾æ—¥å°+åœ°ç·£æ”¿æ²»", "ä¸­åœ‹+äºå¤ªç¶“æ¿Ÿ", "ä¿„ç¾…æ–¯+çƒå…‹è˜­+æ­ç›Ÿ", "ä¸­æ±å±€å‹¢+çŸ³æ²¹+å…¨çƒé‡‘è"]

for idx, tab in enumerate(tabs):
    with tab:
        with st.spinner(f'æ­£åœ¨å³æ™‚æª¢ç´¢ {queries[idx]} å…¨çƒæƒ…å ±...'):
            news_items = fetch_global_news(queries[idx])
            if not news_items:
                st.warning("æš«æ™‚ç„¡æ³•å–å¾—å³æ™‚æ–°èï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            else:
                for n in news_items:
                    # ä½¿ç”¨ Expander å‘ˆç¾ï¼Œå…§å®¹åŒ…å«ä¾†æºã€æ™‚é–“èˆ‡é»æ“Šé€£çµ
                    with st.expander(f"â— {n['title']}", expanded=False):
                        st.markdown(f"**ã€æƒ…å ±ä¾†æºã€‘** {n['source']}")
                        st.markdown(f"**ã€ç™¼å¸ƒæ™‚é–“ã€‘** {n['pubDate']}")
                        st.markdown("---")
                        st.write("é€™æ˜¯ä¸€å‰‡ä¾†è‡ªå…¨çƒä¸»æµåª’é«”çš„å³æ™‚å ±å°ã€‚ç‚ºäº†ç¢ºä¿è³‡è¨Šçš„ 100% çœŸå¯¦æ€§ï¼Œè«‹é»æ“Šä¸‹æ–¹é€£çµç›´æ¥é–±è®€è©³ç›¡çš„æ·±åº¦åˆ†æå…§æ–‡ï¼Œç³»çµ±å·²éæ¿¾é‡è¤‡å…§å®¹ï¼Œç¢ºä¿æä¾›æœ€æ–°å±€å‹¢å‹•æ…‹ã€‚")
                        st.markdown(f"[ğŸ”— é–±è®€å®Œæ•´åŸå§‹å ±å°å…§å®¹]({n['link']})")

